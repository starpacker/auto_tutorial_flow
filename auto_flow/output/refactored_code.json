{
  "data_preprocess": "def load_and_preprocess_data() -> dict:\n    import os\n    import numpy as np\n    import torch\n    import mat73\n    import scipy.io as sio\n\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n    def load_real_data(sample: str, color: str, fit_3D: bool, num_modes: int):\n        # Load the data structure from MAT files\n        file_ext = \"mat\" if sample == 'Siemens' else \"mat\"\n        file_func = sio.loadmat if sample == 'Siemens' else mat73.loadmat\n        data_struct = file_func(f\"data/{sample}/{sample}_{color}.{file_ext}\")\n\n        MAGimg = 3 if sample == 'Siemens' else 2\n        \n        I = data_struct[\"I_low\"].astype(\"float32\")\n\n        if fit_3D:\n            I = I[0:int(num_modes*2), 0:int(num_modes*2), :]\n        else:\n            I = I[0:int(num_modes), 0:int(num_modes), :]\n\n        M, N, ID_len = I.shape\n\n        NAs = data_struct[\"na_calib\"].astype(\"float32\")\n        NAx = NAs[:, 0]\n        NAy = NAs[:, 1]\n\n        wavelength = 0.632 if color == \"r\" else 0.5126 if color == \"g\" else 0.471\n        D_led = 4000\n        k0 = 2 * np.pi / wavelength\n        mag = data_struct[\"mag\"].astype(\"float32\")\n        pixel_size = data_struct[\"dpix_c\"].astype(\"float32\")\n        D_pixel = pixel_size / mag\n        NA = data_struct[\"na_cal\"].astype(\"float32\")\n        kmax = NA * k0\n\n        MM = int(M * MAGimg)\n        NN = int(N * MAGimg)\n\n        Fxx1, Fyy1 = np.meshgrid(np.arange(-NN / 2, NN / 2), np.arange(-MM / 2, MM / 2))\n        Fxx1 = Fxx1[0, :] / (N * D_pixel) * (2 * np.pi)\n        Fyy1 = Fyy1[:, 0] / (M * D_pixel) * (2 * np.pi)\n\n        u = -NAx\n        v = -NAy\n        NAillu = np.sqrt(u**2 + v**2)\n        order = np.argsort(NAillu)\n        u, v = u[order], v[order]\n\n        ledpos_true = np.zeros((ID_len, 2), dtype=int)\n        for idx in range(ID_len):\n            Fx1_temp = np.abs(Fxx1 - k0 * u[idx])\n            Fy1_temp = np.abs(Fyy1 - k0 * v[idx])\n            ledpos_true[idx, 0] = np.argmin(Fx1_temp)\n            ledpos_true[idx, 1] = np.argmin(Fy1_temp)\n\n        Isum = I[:, :, order] / np.max(I)\n\n        kxx, kyy = np.meshgrid(Fxx1[0, :M], Fxx1[0, :N]) if sample == 'Siemens' else np.meshgrid(Fxx1[:M], Fxx1[:N])\n        kxx, kyy = kxx - np.mean(kxx), kyy - np.mean(kyy)\n        krr = np.sqrt(kxx**2 + kyy**2)\n        mask_k = k0**2 - krr**2 > 0\n        kzz = mask_k * np.abs(\n            np.sqrt((k0**2 - krr.astype(\"complex64\") ** 2))\n        ) * np.exp(1j * np.angle(np.sqrt((k0**2 - krr.astype(\"complex64\") ** 2))))\n\n        Fx1, Fy1 = np.meshgrid(np.arange(-N / 2, N / 2), np.arange(-M / 2, M / 2))\n        Fx2 = (Fx1 / (N * D_pixel) * (2 * np.pi)) ** 2\n        Fy2 = (Fy1 / (M * D_pixel) * (2 * np.pi)) ** 2\n        Fxy2 = Fx2 + Fy2\n        Pupil0 = np.zeros((M, N))\n        Pupil0[Fxy2 <= (kmax**2)] = 1\n\n        Pupil0 = torch.from_numpy(Pupil0).view(1, 1, Pupil0.shape[0], Pupil0.shape[1]).to(device)\n        kzz = torch.from_numpy(kzz).to(device).unsqueeze(0)\n        Isum = torch.from_numpy(Isum).to(device)\n\n        if fit_3D:\n            DOF = 0.5 / NA**2\n            delta_z = 0.8 * DOF\n            z_max = 20.0\n            z_min = -20.0\n            num_z = int(np.ceil((z_max - z_min) / delta_z))\n        else:\n            z_min = 0.0\n            z_max = 1.0\n\n        geometry = {\n            \"ledpos_true\": ledpos_true,\n            \"Pupil0\": Pupil0,\n            \"kzz\": kzz,\n            \"Fxx1\": Fxx1,\n            \"Fyy1\": Fyy1,\n            \"z_min\": z_min,\n            \"z_max\": z_max,\n            \"MAGimg\": MAGimg,\n            \"num_z\": num_z if fit_3D else 1\n        }\n        \n        metadata = {\n            \"wavelength\": wavelength,\n            \"D_led\": D_led,\n            \"k0\": k0,\n            \"mag\": mag,\n            \"pixel_size\": pixel_size,\n            \"D_pixel\": D_pixel,\n            \"NA\": NA,\n            \"kmax\": kmax,\n        }\n\n        observed_data = Isum\n\n        return observed_data, geometry, metadata\n\n    # You can modify these parameters as required\n    fit_3D = True\n    sample = \"BloodSmearTilt\"\n    color = \"g\"\n    num_modes = 512\n\n    observed_data, geometry, metadata = load_real_data(sample, color, fit_3D, num_modes)\n    initial_model = None  # Placeholder for initial model Tensor if needed\n\n    return {\n        \"observed_data\": observed_data,\n        \"initial_model\": initial_model,\n        \"geometry\": geometry,\n        \"metadata\": metadata\n    }",
  "forward_operator": "def forward_operator(model: torch.Tensor, geometry: dict) -> torch.Tensor:\n    \"\"\"\n    Forward operator for simulating the optical field propagation in a brightfield microscope setup.\n\n    Parameters:\n    - model: A complex tensor representing the amplitude and phase of the optical field.\n    - geometry: A dictionary containing the geometry and optical parameters such as:\n        - 'led_num': List of LED indices.\n        - 'x_0', 'y_0', 'x_1', 'y_1': Coordinates for sub-spectrum extraction.\n        - 'spectrum_mask': Mask for the spectrum.\n        - 'mag': Magnification factor.\n\n    Returns:\n    - oI_sub: The intensity of the optical field after propagation and sub-spectrum extraction.\n    \"\"\"\n    img_complex = model\n    led_num = geometry['led_num']\n    x_0, y_0 = geometry['x_0'], geometry['y_0']\n    x_1, y_1 = geometry['x_1'], geometry['y_1']\n    spectrum_mask = geometry['spectrum_mask']\n    mag = geometry['mag']\n\n    # Perform Fourier transform to get the spectrum\n    O = torch.fft.fftshift(torch.fft.fft2(img_complex))\n\n    # Padding to match the spectrum mask size\n    to_pad_x = (spectrum_mask.shape[-2] * mag - O.shape[-2]) // 2\n    to_pad_y = (spectrum_mask.shape[-1] * mag - O.shape[-1]) // 2\n    O = F.pad(O, (to_pad_x, to_pad_x, to_pad_y, to_pad_y, 0, 0), \"constant\", 0)\n\n    # Extract sub-spectrum for each LED\n    O_sub = torch.stack(\n        [O[:, x_0[i]:x_1[i], y_0[i]:y_1[i]] for i in range(len(led_num))], dim=1\n    )\n    O_sub = O_sub * spectrum_mask\n\n    # Inverse Fourier transform to get the spatial domain field\n    o_sub = torch.fft.ifft2(torch.fft.ifftshift(O_sub))\n\n    # Calculate the intensity\n    oI_sub = torch.abs(o_sub)\n\n    return oI_sub",
  "inverse_algorithm": "def run_inversion():\n    for epoch in range(num_epochs):\n        led_idices = list(np.arange(ID_len))\n        if fit_3D:\n            dzs = (torch.randperm(num_z - 1)[: num_z // 2] + torch.rand(num_z // 2)) * ((z_max - z_min) // (num_z - 1)) + z_min\n            if epoch % 2 == 0:\n                dzs = torch.linspace(z_min, z_max, num_z).to(device)\n        else:\n            dzs = torch.FloatTensor([0.0]).to(device)\n\n        if use_c2f and c2f_sche[epoch] < model.ds_factor:\n            model.init_scale_grids(ds_factor=c2f_sche[epoch])\n            print(f\"ds_factor changed to {c2f_sche[epoch]}\")\n            model_fn = torch.jit.trace(model, dzs[0:1])\n\n        if epoch == 0:\n            if is_os == \"Windows\":\n                model_fn = torch.jit.trace(model, dzs[0:1])\n            elif is_os == \"Linux\":\n                model_fn = torch.compile(model, backend=\"inductor\")\n            else:\n                raise NotImplementedError\n\n        for dz in dzs:\n            dz = dz.unsqueeze(0)\n\n            for it in range(ID_len // led_batch_size):\n                model.zero_grad()\n                dfmask = torch.exp(1j * kzz.repeat(dz.shape[0], 1, 1) * dz[:, None, None].repeat(1, kzz.shape[1], kzz.shape[2]))\n                led_num = led_idices[it * led_batch_size : (it + 1) * led_batch_size]\n                dfmask = dfmask.unsqueeze(1).repeat(1, len(led_num), 1, 1)\n                spectrum_mask_ampli = Pupil0.repeat(len(dz), len(led_num), 1, 1) * torch.abs(dfmask)\n                spectrum_mask_phase = Pupil0.repeat(len(dz), len(led_num), 1, 1) * (torch.angle(dfmask) + 0)\n                spectrum_mask = spectrum_mask_ampli * torch.exp(1j * spectrum_mask_phase)\n\n                with torch.cuda.amp.autocast(enabled=use_amp, dtype=torch.bfloat16):\n                    img_ampli, img_phase = model_fn(dz)\n                    img_complex = img_ampli * torch.exp(1j * img_phase)\n                    uo, vo = ledpos_true[led_num, 0], ledpos_true[led_num, 1]\n                    x_0, x_1 = vo - M // 2, vo + M // 2\n                    y_0, y_1 = uo - N // 2, uo + N // 2\n\n                    oI_cap = torch.sqrt(Isum[:, :, led_num])\n                    oI_cap = oI_cap.permute(2, 0, 1).unsqueeze(0).repeat(len(dz), 1, 1, 1)\n\n                    predicted = forward_operator(img_complex, geometry=(led_num, x_0, y_0, x_1, y_1, spectrum_mask, MAGimg))\n                    l1_loss = F.smooth_l1_loss(oI_cap, predicted)\n                    loss = l1_loss\n                    mse_loss = F.mse_loss(oI_cap, predicted)\n\n                loss.backward()\n\n                psnr = 10 * -torch.log10(mse_loss).item()\n                t.set_postfix(Loss=f\"{loss.item():.4e}\", PSNR=f\"{psnr:.2f}\")\n                optimizer.step()\n\n        scheduler.step()",
  "evaluation": "To refactor the evaluation part, we need to extract the relevant code for computing PSNR, SSIM, RMSE, and Relative L2, as well as the plotting functionality. Here's how you can do it:\n\n```python\nimport os\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nfrom skimage.metrics import structural_similarity as ssim\n\ndef evaluate_results(\n    observed_data: torch.Tensor,\n    predicted_data: torch.Tensor\n):\n    # Ensure the results directory exists\n    os.makedirs('./results/', exist_ok=True)\n\n    # Convert tensors to numpy arrays\n    observed_np = observed_data.cpu().numpy()\n    predicted_np = predicted_data.cpu().numpy()\n\n    # Compute PSNR\n    psnr_value = psnr(observed_np, predicted_np, data_range=predicted_np.max() - predicted_np.min())\n\n    # Compute SSIM\n    ssim_value = ssim(observed_np, predicted_np, data_range=predicted_np.max() - predicted_np.min())\n\n    # Compute RMSE\n    rmse_value = np.sqrt(np.mean((observed_np - predicted_np) ** 2))\n\n    # Compute Relative L2\n    relative_l2_value = np.linalg.norm(observed_np - predicted_np) / np.linalg.norm(observed_np)\n\n    # Print the evaluation metrics\n    print(f\"PSNR: {psnr_value:.2f}\")\n    print(f\"SSIM: {ssim_value:.4f}\")\n    print(f\"RMSE: {rmse_value:.4f}\")\n    print(f\"Relative L2: {relative_l2_value:.4f}\")\n\n    # Plotting\n    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(30, 10))\n\n    # Plot observed data\n    im = axs[0].imshow(observed_np, cmap=\"gray\")\n    axs[0].axis(\"image\")\n    axs[0].set_title(\"Observed Data\")\n    divider = make_axes_locatable(axs[0])\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    fig.colorbar(im, cax=cax, orientation=\"vertical\")\n\n    # Plot predicted data\n    im = axs[1].imshow(predicted_np, cmap=\"gray\")\n    axs[1].axis(\"image\")\n    axs[1].set_title(\"Predicted Data\")\n    divider = make_axes_locatable(axs[1])\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    fig.colorbar(im, cax=cax, orientation=\"vertical\")\n\n    # Plot difference\n    diff = np.abs(observed_np - predicted_np)\n    im = axs[2].imshow(diff, cmap=\"hot\")\n    axs[2].axis(\"image\")\n    axs[2].set_title(\"Difference\")\n    divider = make_axes_locatable(axs[2])\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    fig.colorbar(im, cax=cax, orientation=\"vertical\")\n\n    # Save the plot\n    plt.savefig('./results/evaluation_plot.png')\n    plt.close()\n\n# Example usage:\n# observed_data = torch.rand((256, 256))  # Example tensor\n# predicted_data = torch.rand((256, 256))  # Example tensor\n# evaluate_results(observed_data, predicted_data)\n```\n\nThis function will compute the required metrics and generate a plot with three subplots: the observed data, the predicted data, and their difference. The plot is saved in the `./results/` directory. Make sure to replace the example usage with actual data when using the function."
}